{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 12A Solution, Fall 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import cos, sin, pi, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this discussion, we will look at an example of how the SVD and pseudoinverse can be used to solve for the minimum norm solution. This discussion will also help you prepare for a homework problem you will have on HW12.\n",
    "\n",
    "For this notebook, we will deal with a graphical example where we are given 2 planes and are asked to find the point on the intersection that is the closest to the origin. We will attempt to use the pseudoinverse as a means of calculating this point. Suppose the equations for the two planes are given as follows:\n",
    "$$\n",
    "    x + y - z = 4 \\\\\n",
    "    x + y + z = 4\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a)\n",
    "Given the equations above, __write the system in matrix-vector form__\n",
    "$$\n",
    "    A\\vec{x} = \\vec{b} \\ \\ \\ \\ \\text{where} \\ \\ \\ \\ \\vec{x} = \n",
    "    \\begin{bmatrix}\n",
    "        x \\\\ y \\\\ z\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "What type of system is this and how many solutions exist?\n",
    "\n",
    "HINT: To create a numpy array for the $2 \\times 2$ identity matrix, you would write np.array([[1,0], [0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 1, -1], [1, 1, 1]])\n",
    "b = np.array([[4], [4]])\n",
    "\n",
    "m, n = A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b)\n",
    "Now let's calculate the SVD of matrix $A$. We have provided you with some skeleton code for the algorithm for calculating the full SVD. It may be helpful to refer to Algorithm 15 on Note 16: https://eecs16b.org/notes/fa22/note16.pdf#page=8. __Fill in the blanks in the algorithm using the note linked above as a reference.__\n",
    "\n",
    "HINT: Some helpful numpy functions include [np.linalg.eig](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html), [np.linalg.matrix_rank](https://numpy.org/doc/stable/reference/generated/numpy.linalg.matrix_rank.html)\n",
    "\n",
    "HINT: To perform matrix multiplication you can use the @ operator (ex: A @ B) and to take the transpose of a matrix use .T (ex: A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullSVD(A):\n",
    "    m, n = A.shape\n",
    "    r = np.linalg.matrix_rank(A)\n",
    "    U_r = np.zeros((m, r))\n",
    "    Sigma_r = np.zeros((r, r))\n",
    "    V_r = np.zeros((n, r))\n",
    "    \n",
    "    eigenvalues, normalized_eigenvectors = np.linalg.eig(A.T @ A)\n",
    "\n",
    "    # Handles sorting of eigenvalues in non-increasing order\n",
    "    idx = eigenvalues.argsort()[::-1]   \n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    normalized_eigenvectors = normalized_eigenvectors[:,idx]\n",
    "\n",
    "    for i in range(r):\n",
    "        sigma_i = sqrt(eigenvalues[i])\n",
    "        v_i = normalized_eigenvectors[:,i]\n",
    "        u_i = A @ v_i / sigma_i\n",
    "\n",
    "        Sigma_r[i][i] = sigma_i\n",
    "        V_r[:,i] = v_i\n",
    "        U_r[:,i] = u_i\n",
    "    \n",
    "    U = ExtendBasis(U_r)\n",
    "    V = ExtendBasis(V_r)\n",
    "    Sigma = np.pad(Sigma_r, [(0, m-r), (0, n-r)])\n",
    "    \n",
    "    return (U, Sigma, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtendBasis(S):\n",
    "    Q, R = np.linalg.qr(S, mode='complete')\n",
    "    return Q "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to solve for the SVD of our $A$ matrix using our defined algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\n",
      "[[-0.70710678 -0.70710678]\n",
      " [-0.70710678  0.70710678]]\n",
      "Sigma:\n",
      "[[2.         0.         0.        ]\n",
      " [0.         1.41421356 0.        ]]\n",
      "V:\n",
      "[[-0.70710678  0.          0.70710678]\n",
      " [-0.70710678  0.         -0.70710678]\n",
      " [-0.         -1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "U, Sigma, V = FullSVD(A)\n",
    "print(\"U:\")\n",
    "print(U)\n",
    "print(\"Sigma:\")\n",
    "print(Sigma)\n",
    "print(\"V:\")\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)\n",
    "Recall that the pseudoinverse of a matrix $A$ with a compact SVD of $A = U_r \\Sigma_r V_r^\\top$ can be written as:\n",
    "$$\n",
    "    A^{\\dagger} := V_r \\Sigma_r^{-1}U_r^{\\top}\n",
    "$$\n",
    "__Calculate the compact pseudoinverse of $A$ and then solve for the minimum norm solution for $\\vec{x}$.__\n",
    "\n",
    "HINT: You may find the following function useful: https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudoinverse: \n",
      " [[ 0.25  0.25]\n",
      " [ 0.25  0.25]\n",
      " [ 0.5  -0.5 ]]\n",
      "Min Norm Solution: \n",
      " [[ 2.0000000e+00]\n",
      " [ 2.0000000e+00]\n",
      " [-4.4408921e-16]]\n"
     ]
    }
   ],
   "source": [
    "r = np.linalg.matrix_rank(A)\n",
    "A_dagger = V[:,:r] @ np.linalg.inv(Sigma[:r,:r]) @ U[:,:r].T \n",
    "min_norm = A_dagger @ b\n",
    "print(\"Pseudoinverse: \\n\", A_dagger)\n",
    "print(\"Min Norm Solution: \\n\", min_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our work by comparing our solution with the solution that numpy calculates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected pseudoinverse: \n",
      " [[ 0.25  0.25]\n",
      " [ 0.25  0.25]\n",
      " [-0.5   0.5 ]]\n",
      "Actual pseudoinverse: \n",
      " [[ 0.25  0.25]\n",
      " [ 0.25  0.25]\n",
      " [ 0.5  -0.5 ]]\n",
      "Expected min norm solution: \n",
      " [[2.0000000e+00]\n",
      " [2.0000000e+00]\n",
      " [8.8817842e-16]]\n",
      "Actual min norm solution: \n",
      " [[ 2.0000000e+00]\n",
      " [ 2.0000000e+00]\n",
      " [-4.4408921e-16]]\n"
     ]
    }
   ],
   "source": [
    "A_dagger_np = np.linalg.pinv(A)\n",
    "min_norm_np = A_dagger_np @ b\n",
    "\n",
    "print(\"Expected pseudoinverse: \\n\", A_dagger_np)\n",
    "print(\"Actual pseudoinverse: \\n\", A_dagger)\n",
    "print(\"Expected min norm solution: \\n\", min_norm_np)\n",
    "print(\"Actual min norm solution: \\n\", min_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d)\n",
    "Recall that for a wide matrix $A \\in \\mathbb{R}^{m \\times n}$ where $m \\leq n$ and rank($A$) = $m$ ($A$ has full row rank), the pseudoinverse can be represented as\n",
    "$$\n",
    "    A^\\dagger = A^\\top (AA^\\top)^{-1}\n",
    "$$\n",
    "__Use this definition of the pseudoinverse to solve for the minimum norm solution and show that they are the same.__\n",
    "\n",
    "HINT: You may find the following function useful: https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html. Also recall that matrix multiplication uses the operator @."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pseudoinverse: \n",
      " [[ 0.25  0.25]\n",
      " [ 0.25  0.25]\n",
      " [-0.5   0.5 ]]\n",
      "Min Norm Solution: \n",
      "  [[2.]\n",
      " [2.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "A_dagger_full_rank = A.T @ np.linalg.inv(A @ A.T)\n",
    "min_norm_full_rank = A_dagger_full_rank @ b\n",
    "print(\"Pseudoinverse: \\n\", A_dagger_full_rank)\n",
    "print(\"Min Norm Solution: \\n \", min_norm_full_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (e)\n",
    "Suppose we tried to use the following form of the pseudoinverse to calculate the minimum norm solution for our problem:\n",
    "$$\n",
    "    A^\\dagger =  (A^\\top A)^{-1}A^\\top\n",
    "$$\n",
    "__Why does or doesn't this form of the pseudoinverse work for solving our problem? Verify your response below.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A_dagger_ls \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(A\u001b[39m.\u001b[39;49mT \u001b[39m@\u001b[39;49m A) \u001b[39m@\u001b[39m A\u001b[39m.\u001b[39mT\n\u001b[1;32m      2\u001b[0m min_norm_ls \u001b[39m=\u001b[39m A_dagger_ls \u001b[39m@\u001b[39m b\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPseudoinverse: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, A_dagger_ls)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/linalg/linalg.py:552\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    550\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    551\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 552\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    553\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/linalg/linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "A_dagger_ls = np.linalg.inv(A.T @ A) @ A.T\n",
    "min_norm_ls = A_dagger_ls @ b\n",
    "print(\"Pseudoinverse: \\n\", A_dagger_ls)\n",
    "print(\"Min Norm Solution: \\n \", min_norm_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plugged in the pseudoinverse formula and attempted to calculate it, you should've run into a \"LinAlgError: Singular matrix\" error. Essentially this error states that you have a square matrix that doesn't have an inverse. In this case, $A\\top A$ is not invertible, since we only have a rank 2 $A$ matrix so $A\\top A$ will not be full rank. Therefore it is not invertible and this form of the pseudoinverse wouldn't work for an underdetermined/wide system. This formula solves the least squares problem where we have an overdetermined system and are trying to solve for the best estimate of $\\vec{b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors:\n",
    "- Oliver Yu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
